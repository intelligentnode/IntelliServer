const express = require('express');
var path = require('path');
const router = express.Router();
const { LLMEvaluation } = require('intellinode');
const { USE_DEFAULT_KEYS } = require(path.join(global.__basedir, 'config'));
require('dotenv').config();

const keys = {
  'openai': process.env.OPENAI_API_KEY,
  'cohere': process.env.COHERE_API_KEY,
  'replicate': process.env.REPLICATE_API_KEY,
  'huggingface': process.env.HUGGING_API_KEY,
};

function getModelSettings(input) {
  return input.map((item) => {
    return {
      ...item,
      apiKey: (USE_DEFAULT_KEYS && !item.apiKey) ? keys[item.provider.toLowerCase()] : item.apiKey,
    };
  });
}

function getLLMEvaluation(req) {
  const apiKey = (USE_DEFAULT_KEYS && !req.body.semantic.api_key) ?
                 keys[req.body.semantic.provider.toLowerCase()] : req.body.semantic.api_key;

  return new LLMEvaluation(apiKey, req.body.semantic.provider);
}

/**
 * @swagger
 * /evaluate/llm:
 *   post:
 *     tags:
 *       - Functions
 *     summary: Evaluate Language models comparison against defined answers using LLM providers like openai, cohere, etc.
 *
 *     security:
 *       - ApiKeyAuth: []
 *
 *     requestBody:
 *       required: true
 *       content:
 *         application/json:
 *           schema:
 *             type: object
 *             required:
 *               - userInput
 *               - targetAnswers
 *             properties:
 *               userInput:
 *                 type: string
 *                 description: The user input string for the language models.
 *               targetAnswers:
 *                 type: array
 *                 items:
 *                   type: string
 *                 description: Array of target answers against which language models' outputs are compared.
 *               semantic:
 *                 type: object
 *                 properties:
 *                   api_key:
 *                     type: string
 *                     description: The api key for semantic provider.
 *                   provider:
 *                     type: string
 *                     description: The provider name for semantic comparison, e.g. 'openai'.
 *               evaluate:
 *                 type: array
 *                 items:
 *                   type: object
 *                   properties:
 *                     apiKey:
 *                       type: string
 *                       description: The api key for the language model provider.
 *                     provider:
 *                       type: string
 *                       description: The provider name, e.g. 'openai'.
 *                     type:
 *                       type: string
 *                       description: The type of language model e.g. 'completion', 'chat'.
 *                     model:
 *                       type: string
 *                       description: The name of the language model to be used.
 *                     maxTokens:
 *                       type: integer
 *                       description: The maximum number of tokens to be generated by language model.
 *                     temperature:
 *                       type: float
 *                       description: The randomness parameter for the output generation.
 *     responses:
 *       200:
 *         description: The comparison results of the language models.
 *       400:
 *         description: There was a problem with the request.
 */
router.post('/llm', async (req, res, next) => {
  try {
    const llmEvaluation = getLLMEvaluation(req);
    const userInput = req.body.userInput;
    const targetAnswers = req.body.targetAnswers;
    const models = getModelSettings(req.body.evaluate);

    console.log('models input: ', models)

    const results = await llmEvaluation.compareModels(userInput, targetAnswers, models);
    res.json({ status: 'OK', results: results });
  } catch (error) {
    res.json({ status: 'ERROR', message: error.message });
  }
});

module.exports = router;